{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import sqlalchemy\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import *\n",
    "\n",
    "import Preprocessing\n",
    "from Preprocessing import preprocess_data\n",
    "\n",
    "import model_selection \n",
    "from model_selection import train_and_save_best_model\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from datetime import datetime, timedelta\n",
    "import time  \n",
    "import pytz    \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso, HuberRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_creds = {\n",
    "    'USER_NAME': '',\n",
    "    'PASSWORD': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the connection engine (way 1)\n",
    "engine = create_engine(URL(\n",
    "        account=\"tr09543.ap-south-1\",\n",
    "        user= snowflake_creds.USER_NAME,\n",
    "        password= snowflake_creds.PASSWORD,\n",
    "        role=\"ACCOUNTADMIN\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"HEALTHDB\",\n",
    "        schema=\"HEALTHSCHEMA\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "WITH BASE AS (\n",
    "    SELECT\n",
    "        CASE_ID,\n",
    "        COALESCE(HOSPITAL_CODE, 0) AS HOSPITAL_CODE,\n",
    "        COALESCE(HOSPITAL_TYPE_CODE, 'None') AS HOSPITAL_TYPE_CODE,\n",
    "        COALESCE(CITY_CODE_HOSPITAL, 0) AS CITY_CODE_HOSPITAL,\n",
    "        COALESCE(HOSPITAL_REGION_CODE, 'None') AS HOSPITAL_REGION_CODE,\n",
    "        COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL, 0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "        COALESCE(DEPARTMENT, 'None') AS DEPARTMENT,\n",
    "        COALESCE(WARD_TYPE, 'None') AS WARD_TYPE,\n",
    "        COALESCE(WARD_FACILITY_CODE, 'None') AS WARD_FACILITY_CODE,\n",
    "        COALESCE(BED_GRADE, 0) AS BED_GRADE,\n",
    "        PATIENTID,\n",
    "        COALESCE(CITY_CODE_PATIENT, 0) AS CITY_CODE_PATIENT,\n",
    "        COALESCE(TYPE_OF_ADMISSION, 'None') AS TYPE_OF_ADMISSION,\n",
    "        COALESCE(SEVERITY_OF_ILLNESS, 'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "        COALESCE(VISITORS_WITH_PATIENT, 0) AS VISITORS_WITH_PATIENT,\n",
    "        COALESCE(AGE, 'None') AS AGE,\n",
    "        COALESCE(ADMISSION_DEPOSIT, 0) AS ADMISSION_DEPOSIT,\n",
    "        ADMISSION_DATE,\n",
    "        DISCHARGE_DATE\n",
    "    FROM HEALTHDB.HEALTHSCHEMA.HEALTH_DATA\n",
    "    WHERE ADMISSION_DATE IS NOT NULL AND DISCHARGE_DATE IS NOT NULL -- Ensure dates are valid\n",
    "),\n",
    "    \n",
    "BASE_WITH_FEATURES AS (\n",
    "    SELECT *,\n",
    "        -- Extract year, month, and day as separate columns\n",
    "        YEAR(ADMISSION_DATE) AS ADMISSION_YEAR,\n",
    "        MONTH(ADMISSION_DATE) AS ADMISSION_MONTH,\n",
    "        DAY(ADMISSION_DATE) AS ADMISSION_DAY,\n",
    "        MONTHNAME(ADMISSION_DATE) AS ADMISSION_MONTH_NAME,\n",
    "        DAYNAME(ADMISSION_DATE) AS ADMISSION_DAY_NAME,\n",
    "        CONCAT(TYPE_OF_ADMISSION, '-', SEVERITY_OF_ILLNESS) AS ADMISSION_ILLNESS_COMB,\n",
    "        CONCAT(SEVERITY_OF_ILLNESS, '-', CAST(BED_GRADE AS VARCHAR)) AS ILLNESS_BEDGRADE_COMB,\n",
    "        CONCAT(DEPARTMENT, '-', SEVERITY_OF_ILLNESS) AS DEPARTMENT_ILLNESS_COMB,\n",
    "        CASE -- Additional categorization using CASE statement\n",
    "            WHEN DATEDIFF(day, ADMISSION_DATE, DISCHARGE_DATE) <= 7 THEN 'Short Stay'\n",
    "            WHEN DATEDIFF(day, ADMISSION_DATE, DISCHARGE_DATE) <= 14 THEN 'Medium Stay'\n",
    "            ELSE 'Long Stay'\n",
    "        END AS STAY_DURATION,\n",
    "        DATEDIFF(day, ADMISSION_DATE, DISCHARGE_DATE) AS LENGHTH_OF_STAY -- Length of Stay\n",
    "    FROM BASE\n",
    "    WHERE DISCHARGE_DATE >= ADMISSION_DATE -- Ensure logical discharge dates\n",
    ")\n",
    "\n",
    "SELECT * FROM BASE_WITH_FEATURES WHERE ADMISSION_DATE = CURRENT_DATE-45\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_n_create_model_features(df,feat_list):\n",
    "    test = pd.DataFrame()\n",
    "    for col in feat_list:\n",
    "        if col in df.columns.tolist():\n",
    "            test[col] = df[col]\n",
    "        else:\n",
    "            test[col] = 0\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_predictions_to_snowflake_table(data):\n",
    "    import pandas\n",
    "    import snowflake.connector\n",
    "    from snowflake.connector.pandas_tools import pd_writer, write_pandas\n",
    "\n",
    "    engine = create_engine(URL(\n",
    "            account=\"tr09543.ap-south-1\",\n",
    "            user= snowflake_creds.USER_NAME,\n",
    "            password= snowflake_creds.PASSWORD,\n",
    "            role=\"ACCOUNTADMIN\",\n",
    "            warehouse=\"COMPUTE_WH\",\n",
    "            database=\"HEALTHDB\",\n",
    "            schema=\"HEALTHSCHEMA\"\n",
    "        ))  \n",
    "    \n",
    "    # Creating the logging table if not exists already\n",
    "    table = 'TEMP_LOS_PREDICTION_MODEL_LOGGING_TABLE_HARI'\n",
    "    \n",
    "    # Inserting the data to snowflake logging table\n",
    "    data.to_sql(table, engine, index=False, if_exists='append', method=pd_writer)\n",
    "    return 'Success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    \n",
    "    # Loading the scoring data\n",
    "    score_data = pd.DataFrame(pd.read_sql(query,conn))\n",
    "    score_data.columns = [col.upper() for col in score_data.columns.tolist()]\n",
    "    \n",
    "    # Applying the preprocessing steps\n",
    "    score_data_processed = Preprocessing.preprocess_data(score_data)\n",
    "    \n",
    "    # Applying feature selection\n",
    "    final_feats = pd.read_pickle('MODEL_FEATS.pkl')\n",
    "    score_data_final = check_n_create_model_features(score_data_processed,final_feats)\n",
    "    \n",
    "    # Getting the predictions\n",
    "    #model = xgboost.XGBRegressor()\n",
    "    #model.load_model('MODEL_XGB.model')\n",
    "    #score_data_final['PREDICTED_LOS'] = np.ceil(model.predict(score_data_final.drop('LOS',axis=1)))\n",
    "    \n",
    "    # Writing the dataframe to snowflake as a table\n",
    "    #score_data_final = score_data_final.reset_index()\n",
    "    #score_data_table = pd.merge(score_data,score_data_final,on='CASE_ID',how='left')\n",
    "    #status = insert_predictions_to_snowflake_table(score_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test split\n",
    "X = score_data_final.drop('LENGTH_OF_STAY',axis=1)\n",
    "y = score_data_final[['LENGTH_OF_STAY']]\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.3,stratify=y,random_state=123)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_selection \n",
    "from model_selection import train_and_save_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save_best_model(train_and_save_best_model(x_train, y_train, x_test, y_test, \"best_regression_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = joblib.load(\"best_regression_model.pkl\")\n",
    "\n",
    "# Now, you can use the best model for predictions\n",
    "model = None  # Initialize the model variable\n",
    "\n",
    "if isinstance(best_model, LinearRegression):\n",
    "    model = LinearRegression()\n",
    "elif isinstance(best_model, RandomForestRegressor):\n",
    "    model = RandomForestRegressor()\n",
    "elif isinstance(best_model, xgb.XGBRegressor):\n",
    "    model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model('MODEL_XGB.model')\n",
    "score_data_final['PREDICTED_LOS'] = np.ceil(model.predict(score_data_final.drop('LENGTH_OF_STAY',axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the dataframe to snowflake as a table\n",
    "score_data_final = score_data_final.reset_index()\n",
    "score_data_table = pd.merge(score_data,score_data_final,on='CASE_ID',how='left')\n",
    "status = insert_predictions_to_snowflake_table(score_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_data.shape)\n",
    "score_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_data_processed.shape)\n",
    "score_data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_data_final.shape)\n",
    "score_data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_data_table.shape)\n",
    "score_data_table.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
