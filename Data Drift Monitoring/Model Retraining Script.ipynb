{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import sqlalchemy\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import *\n",
    "\n",
    "import xgboost as xgb\n",
    "from datetime import datetime, timedelta\n",
    "import time  \n",
    "import pytz    \n",
    "\n",
    "import Preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_creds = {\n",
    "    'USER_NAME': 'omarhamzic',\n",
    "    'PASSWORD': 'Werewolf123!@#'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the connection engine (way 1)\n",
    "engine = create_engine(URL(\n",
    "        account=\"cr21746.ap-south-1\",\n",
    "        user= snowflake_creds['USER_NAME'],\n",
    "        password= snowflake_creds['PASSWORD'],\n",
    "        role=\"ACCOUNTADMIN\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"HEALTHDB\",\n",
    "        schema=\"HEALTHSCHEMA\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retraining_batch_query(a):\n",
    "    query = f\"\"\"\n",
    "\n",
    "        WITH TRAIN_BASE AS (\n",
    "\n",
    "            SELECT CASE_ID,\n",
    "                   COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "                   COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "                   COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "                   COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "                   COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "                   COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "                   COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "                   COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "                   COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "                   PATIENTID,\n",
    "                   COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "                   COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "                   COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "                   COALESCE(VISITORS_WITH_PATIENT,0) AS VISITORS_WITH_PATIENT,\n",
    "                   COALESCE(AGE,'None') AS AGE,\n",
    "                   COALESCE(ADMISSION_DEPOSIT,0) AS ADMISSION_DEPOSIT,\n",
    "                   ADMISSION_DATE,\n",
    "                   DISCHARGE_DATE\n",
    "\n",
    "            FROM HEALTHDB.HEALTHSCHEMA.HEALTH_DATA\n",
    "            WHERE ADMISSION_DATE >= '2022-11-01' --- to reduce the load\n",
    "\n",
    "        ),\n",
    "\n",
    "        TRAIN_BASE_WITH_FEATURES AS (\n",
    "\n",
    "            SELECT *,\n",
    "                    MONTHNAME(ADMISSION_DATE) AS ADMISSION_MONTH,\n",
    "                    DAYNAME(ADMISSION_DATE) AS ADMISSION_DAY,    \n",
    "                    CONCAT(TYPE_OF_ADMISSION,'-',SEVERITY_OF_ILLNESS) AS ADMISSION_ILLNESS,\n",
    "                    CONCAT(SEVERITY_OF_ILLNESS,'-',BED_GRADE) AS ILLNESS_BEDGRADE,\n",
    "                    CONCAT(DEPARTMENT,'-',SEVERITY_OF_ILLNESS) AS DEPARTMENT_ILLNESS,\n",
    "                    DATEDIFF(day,ADMISSION_DATE,DISCHARGE_DATE) AS LOS\n",
    "            FROM TRAIN_BASE \n",
    "\n",
    "        ),    \n",
    "\n",
    "        NEW_DATA_WITH_FEATURES AS (\n",
    "\n",
    "             SELECT CASE_ID,\n",
    "                       COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "                       COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "                       COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "                       COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "                       COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL_X,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "                       COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "                       COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "                       COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "                       COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "                       PATIENTID,\n",
    "                       COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "                       COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "                       COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "                       COALESCE(VISITORS_WITH_PATIENT_X,0) AS VISITORS_WITH_PATIENT,\n",
    "                       COALESCE(AGE,'None') AS AGE,\n",
    "                       COALESCE(ADMISSION_DEPOSIT_X,0) AS ADMISSION_DEPOSIT,\n",
    "                       ADMISSION_DATE,\n",
    "                       DISCHARGE_DATE,\n",
    "                       ADMISSION_MONTH,\n",
    "                       ADMISSION_DAY,\n",
    "                       ADMISSION_ILLNESS,\n",
    "                       ILLNESS_BEDGRADE,\n",
    "                       DEPARTMENT_ILLNESS,\n",
    "                       LOS_X AS LOS \n",
    "                    FROM HEALTHDB.HEALTHSCHEMA.TEMP_LOS_PREDICTION_MODEL_LOGGING_TABLE_HARI\n",
    "                    WHERE ADMISSION_DATE >= CURRENT_DATE-144+{a*7} AND ADMISSION_DATE < CURRENT_DATE-144+{(a+1)*7}    \n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        SELECT * FROM TRAIN_BASE_WITH_FEATURES\n",
    "        UNION ALL\n",
    "        SELECT * FROM NEW_DATA_WITH_FEATURES;\n",
    "\n",
    "        \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    data = pd.DataFrame(pd.read_sql(retraining_batch_query(0),conn))\n",
    "    data.columns = [col.upper() for col in data.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_n_create_model_features(df,feat_list):\n",
    "    test = pd.DataFrame()\n",
    "    for col in feat_list:\n",
    "        if col in df.columns.tolist():\n",
    "            test[col] = df[col]\n",
    "        else:\n",
    "            test[col] = 0\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    # Creating X and Y\n",
    "    x_train = df.drop('LOS',axis=1)\n",
    "    y_train = df[['LOS']]\n",
    "    \n",
    "    # Decision Tree\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    dtree = DecisionTreeRegressor()\n",
    "    dtree.fit(x_train,y_train)\n",
    "    # Feature Importance\n",
    "    feat_imp = (pd.DataFrame(zip(x_train.columns,dtree.feature_importances_),columns=['feature','imp'])\n",
    "                .sort_values(by='imp',ascending=False))\n",
    "    final_features_dtree = feat_imp[feat_imp['imp']>=0.01]['feature'].values.tolist()\n",
    "    \n",
    "    # XGBoost\n",
    "    import xgboost as xgb\n",
    "\n",
    "    xgb_ = xgb.XGBRegressor()\n",
    "    xgb_.fit(x_train,y_train)\n",
    "    # Feature Importance\n",
    "    feat_imp = (pd.DataFrame(zip(x_train.columns,xgb_.feature_importances_),columns=['feature','imp'])\n",
    "                .sort_values(by='imp',ascending=False))\n",
    "    final_features_xgb = feat_imp[feat_imp['imp']>=0.01]['feature'].values.tolist()\n",
    "    \n",
    "    model_features =  list(set(final_features_dtree).union(set(final_features_xgb)))\n",
    "    print(\"Final Features from both Dtree & XGB: \"+str(len(model_features)))\n",
    "    \n",
    "    import pickle\n",
    "\n",
    "    final_feats_list = model_features+['LOS']\n",
    "\n",
    "    with open('./Retraining Artifacts/MODEL_FEATS.pkl','wb') as F:\n",
    "        pickle.dump(final_feats_list,F)\n",
    "    \n",
    "    return final_feats_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_feats.remove('LOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Omar Hamzic\\Documents\\P4 Snowflake Healthcare Analytics Project\\Model Retraining Script.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Omar%20Hamzic/Documents/P4%20Snowflake%20Healthcare%20Analytics%20Project/Model%20Retraining%20Script.ipynb#X13sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m rmse, mae\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Omar%20Hamzic/Documents/P4%20Snowflake%20Healthcare%20Analytics%20Project/Model%20Retraining%20Script.ipynb#X13sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Omar%20Hamzic/Documents/P4%20Snowflake%20Healthcare%20Analytics%20Project/Model%20Retraining%20Script.ipynb#X13sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39m# Establish a database connection (engine)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Omar%20Hamzic/Documents/P4%20Snowflake%20Healthcare%20Analytics%20Project/Model%20Retraining%20Script.ipynb#X13sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mwith\u001b[39;00m engine\u001b[39m.\u001b[39mconnect() \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Omar%20Hamzic/Documents/P4%20Snowflake%20Healthcare%20Analytics%20Project/Model%20Retraining%20Script.ipynb#X13sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         \u001b[39m# Load scoring data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Omar%20Hamzic/Documents/P4%20Snowflake%20Healthcare%20Analytics%20Project/Model%20Retraining%20Script.ipynb#X13sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         data \u001b[39m=\u001b[39m load_scoring_data(conn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Omar%20Hamzic/Documents/P4%20Snowflake%20Healthcare%20Analytics%20Project/Model%20Retraining%20Script.ipynb#X13sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         \u001b[39m# Split data into train and test sets\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "def load_scoring_data(conn):\n",
    "    # Loading the scoring data\n",
    "    data = pd.DataFrame(pd.read_sql(retraining_batch_query(0), conn))\n",
    "    data.columns = [col.upper() for col in data.columns.tolist()]\n",
    "    return data\n",
    "\n",
    "def split_data_by_date(data):\n",
    "    # Splitting the data into Train and Test set\n",
    "    tz_NY = pytz.timezone('America/New_York')\n",
    "    max_date = data.ADMISSION_DATE.max()\n",
    "    min_date = max_date - timedelta(days=7)\n",
    "    data_train = data[data['ADMISSION_DATE'] <= min_date]\n",
    "    data_test = data[(data['ADMISSION_DATE'] >= min_date) & (data['ADMISSION_DATE'] <= max_date)]\n",
    "    return data_train, data_test\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Applying preprocessing steps\n",
    "    df_processed = Preprocessing.preprocess_data(data)\n",
    "    return df_processed\n",
    "\n",
    "def train_model(df_train, model_feats):\n",
    "    # Performing feature selection\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.fit(df_train[model_feats], df_train['LOS'])\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, df_test, model_feats):\n",
    "    # Evaluating the model\n",
    "    df_test_final = check_n_create_model_features(df_test, model_feats)\n",
    "    if 'LOS' in df_test_final.columns.tolist():\n",
    "        df_test_final = df_test_final.drop('LOS', axis=1)\n",
    "    preds = np.ceil(model.predict(df_test_final))\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(df_test['LOS'], preds))\n",
    "    mae = np.sqrt(metrics.mean_absolute_error(df_test['LOS'], preds))\n",
    "    return rmse, mae\n",
    "\n",
    "def save_trained_model(model, model_metrics):\n",
    "    # Saving the trained model and its performance metrics\n",
    "    model.get_booster().save_model('./Retraining Artifacts/MODEL_XGB.model')\n",
    "    with open('./Retraining Artifacts/MODEL_XGB_PERFM_METRICS.pkl', 'wb') as F:\n",
    "        pickle.dump(model_metrics, F)\n",
    "\n",
    "def load_old_model_and_predict(df_test, model_feats_old):\n",
    "    # Loading the old model and making predictions\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.load_model('MODEL_XGB.model')\n",
    "    df_test_final = check_n_create_model_features(df_test, model_feats_old)\n",
    "    if 'LOS' in df_test_final.columns.tolist():\n",
    "        df_test_final = df_test_final.drop('LOS', axis=1)\n",
    "    preds = np.ceil(model.predict(df_test_final))\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(df_test['LOS'], preds))\n",
    "    mae = np.sqrt(metrics.mean_absolute_error(df_test['LOS'], preds))\n",
    "    return rmse, mae\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Establish a database connection (engine)\n",
    "    with engine.connect() as conn:\n",
    "        # Load scoring data\n",
    "        data = load_scoring_data(conn)\n",
    "\n",
    "        # Split data into train and test sets\n",
    "        data_train, data_test = split_data_by_date(data)\n",
    "\n",
    "        # Preprocess the data\n",
    "        df_train_processed = preprocess_data(data_train)\n",
    "        df_test_processed = preprocess_data(data_test)\n",
    "\n",
    "        # Train the model\n",
    "        model_feats = feature_selection(df_train_processed)\n",
    "        model_feats.remove('LOS')\n",
    "        model = train_model(df_train_processed, model_feats)\n",
    "\n",
    "        # Evaluate the new model\n",
    "        rmse_new, mae_new = evaluate_model(model, df_test_processed, model_feats)\n",
    "        print(\"\\nTest Performance (new model)\")\n",
    "        print(\"RMSE:\", rmse_new)\n",
    "        print(\"MAE:\", mae_new)\n",
    "\n",
    "        # Save the trained model and its performance metrics\n",
    "        model_xgb_metrics_new = {'RMSE': rmse_new, 'MAE': mae_new}\n",
    "        save_trained_model(model, model_xgb_metrics_new)\n",
    "        \n",
    "        # Load the old model and evaluate\n",
    "        with open('MODEL_FEATS.pkl','rb') as F:\n",
    "            model_feats_old = pickle.load(F)\n",
    "        rmse_old, mae_old = load_old_model_and_predict(df_test_processed, model_feats_old)\n",
    "        print(\"\\nTest Performance (old model)\")\n",
    "        print(\"RMSE:\", rmse_old)\n",
    "        print(\"MAE:\", mae_old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_feats_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Final Functions/Scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_n_create_model_features(df,feat_list):\n",
    "    test = pd.DataFrame()\n",
    "    for col in feat_list:\n",
    "        if col in df.columns.tolist():\n",
    "            test[col] = df[col]\n",
    "        else:\n",
    "            test[col] = 0\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "def feature_selection(df):\n",
    "    # Creating X and Y\n",
    "    x_train = df.drop('LOS', axis=1)\n",
    "    y_train = df['LOS']\n",
    "\n",
    "    # Decision Tree\n",
    "    dtree = DecisionTreeRegressor()\n",
    "    dtree.fit(x_train, y_train)\n",
    "    \n",
    "    # Feature Importance for Decision Tree\n",
    "    feat_imp_dtree = pd.DataFrame(zip(x_train.columns, dtree.feature_importances_), columns=['feature', 'imp'])\n",
    "    final_features_dtree = feat_imp_dtree[feat_imp_dtree['imp'] >= 0.01]['feature'].tolist()\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_ = xgb.XGBRegressor()\n",
    "    xgb_.fit(x_train, y_train)\n",
    "\n",
    "    # Feature Importance for XGBoost\n",
    "    feat_imp_xgb = pd.DataFrame(zip(x_train.columns, xgb_.feature_importances_), columns=['feature', 'imp'])\n",
    "    final_features_xgb = feat_imp_xgb[feat_imp_xgb['imp'] >= 0.01]['feature'].tolist()\n",
    "\n",
    "    # Combine features from both models\n",
    "    model_features = list(set(final_features_dtree).union(set(final_features_xgb)))\n",
    "    print(\"Final Features from both Decision Tree and XGBoost: \" + str(len(model_features)))\n",
    "\n",
    "    # Save the final feature list including the target variable 'LOS'\n",
    "    final_feats_list = model_features + ['LOS']\n",
    "\n",
    "    with open('./Retraining Artifacts/MODEL_FEATS.pkl', 'wb') as F:\n",
    "        pickle.dump(final_feats_list, F)\n",
    "\n",
    "    return final_feats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retraining_batch_query(max_date):\n",
    "    query = f\"\"\"\n",
    "\n",
    "        WITH TRAIN_BASE AS (\n",
    "\n",
    "            SELECT CASE_ID,\n",
    "                   COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "                   COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "                   COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "                   COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "                   COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "                   COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "                   COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "                   COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "                   COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "                   PATIENTID,\n",
    "                   COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "                   COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "                   COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "                   COALESCE(VISITORS_WITH_PATIENT,0) AS VISITORS_WITH_PATIENT,\n",
    "                   COALESCE(AGE,'None') AS AGE,\n",
    "                   COALESCE(ADMISSION_DEPOSIT,0) AS ADMISSION_DEPOSIT,\n",
    "                   ADMISSION_DATE,\n",
    "                   DISCHARGE_DATE\n",
    "\n",
    "            FROM HEALTHDB.HEALTHSCHEMA.HEALTH_DATA\n",
    "            WHERE ADMISSION_DATE >= '2022-11-01' --- To reduce the load\n",
    "\n",
    "        ),\n",
    "\n",
    "        TRAIN_BASE_WITH_FEATURES AS (\n",
    "\n",
    "            SELECT *,\n",
    "                    MONTHNAME(ADMISSION_DATE) AS ADMISSION_MONTH,\n",
    "                    DAYNAME(ADMISSION_DATE) AS ADMISSION_DAY,    \n",
    "                    CONCAT(TYPE_OF_ADMISSION,'-',SEVERITY_OF_ILLNESS) AS ADMISSION_ILLNESS,\n",
    "                    CONCAT(SEVERITY_OF_ILLNESS,'-',BED_GRADE) AS ILLNESS_BEDGRADE,\n",
    "                    CONCAT(DEPARTMENT,'-',SEVERITY_OF_ILLNESS) AS DEPARTMENT_ILLNESS,\n",
    "                    DATEDIFF(day,ADMISSION_DATE,DISCHARGE_DATE) AS LOS\n",
    "            FROM TRAIN_BASE \n",
    "\n",
    "        ),    \n",
    "\n",
    "        NEW_DATA_WITH_FEATURES AS (\n",
    "\n",
    "             SELECT CASE_ID,\n",
    "                       COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "                       COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "                       COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "                       COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "                       COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL_X,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "                       COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "                       COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "                       COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "                       COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "                       PATIENTID,\n",
    "                       COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "                       COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "                       COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "                       COALESCE(VISITORS_WITH_PATIENT_X,0) AS VISITORS_WITH_PATIENT,\n",
    "                       COALESCE(AGE,'None') AS AGE,\n",
    "                       COALESCE(ADMISSION_DEPOSIT_X,0) AS ADMISSION_DEPOSIT,\n",
    "                       ADMISSION_DATE,\n",
    "                       DISCHARGE_DATE,\n",
    "                       ADMISSION_MONTH,\n",
    "                       ADMISSION_DAY,\n",
    "                       ADMISSION_ILLNESS,\n",
    "                       ILLNESS_BEDGRADE,\n",
    "                       DEPARTMENT_ILLNESS,\n",
    "                       LOS_X AS LOS \n",
    "                    FROM HEALTHDB.HEALTHSCHEMA.TEMP_LOS_PREDICTION_MODEL_LOGGING_TABLE_HARI\n",
    "                    WHERE ADMISSION_DATE < '{max_date}'\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        SELECT * FROM TRAIN_BASE_WITH_FEATURES\n",
    "        UNION ALL\n",
    "        SELECT * FROM NEW_DATA_WITH_FEATURES;\n",
    "\n",
    "        \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def retrain_and_evaluate_model(cut_off_date):\n",
    "    with engine.connect() as conn:\n",
    "        # Loading the scoring data\n",
    "        data = pd.DataFrame(pd.read_sql(retraining_batch_query(cut_off_date), conn))\n",
    "        data.columns = [col.upper() for col in data.columns.tolist()]\n",
    "    \n",
    "    # Splitting the data into Train and Test set\n",
    "    tz_NY = pytz.timezone('America/New_York')\n",
    "    max_date = data.ADMISSION_DATE.max()\n",
    "    min_date = max_date - timedelta(days=7)\n",
    "    data_train = data[data['ADMISSION_DATE'] <= min_date]\n",
    "    data_test = data[(data['ADMISSION_DATE'] >= min_date) & (data['ADMISSION_DATE'] <= max_date)]\n",
    "\n",
    "    # Preprocess the data\n",
    "    df_train_processed = Preprocessing.preprocess_data(data_train)\n",
    "    df_test_processed = Preprocessing.preprocess_data(data_test)\n",
    "\n",
    "    # Performing feature selection\n",
    "    df_final = df_train_processed.copy()\n",
    "    model_feats = feature_selection(df_final)\n",
    "    model_feats.remove('LOS')\n",
    "\n",
    "    # Train the new model\n",
    "    xgb_ = xgb.XGBRegressor()\n",
    "    xgb_.fit(df_final[model_feats], df_final['LOS'])\n",
    "\n",
    "    # Evaluate the new model\n",
    "    df_test_final = check_n_create_model_features(df_test_processed, model_feats)\n",
    "    if 'LOS' in df_test_final.columns.tolist():\n",
    "        df_test_final = df_test_final.drop('LOS', axis=1)\n",
    "    preds_new = np.ceil(xgb_.predict(df_test_final))\n",
    "    rmse_new = np.sqrt(metrics.mean_squared_error(df_test_processed['LOS'], preds_new))\n",
    "    mae_new = np.sqrt(metrics.mean_absolute_error(df_test_processed['LOS'], preds_new))\n",
    "\n",
    "    # Save the trained new model and its performance metrics\n",
    "    booster = xgb_.get_booster()\n",
    "    booster.save_model('./Retraining Artifacts/MODEL_XGB.model')\n",
    "    model_xgb_metrics_new = {'RMSE': rmse_new, 'MAE': mae_new}\n",
    "    with open('./Retraining Artifacts/MODEL_XGB_PERFM_METRICS.pkl', 'wb') as F:\n",
    "        pickle.dump(model_xgb_metrics_new, F)\n",
    "\n",
    "    # Load the old model and evaluate\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.load_model('MODEL_XGB.model')\n",
    "    with open('MODEL_FEATS.pkl', 'rb') as F:\n",
    "        model_feats_old = pickle.load(F)\n",
    "    df_test_final = check_n_create_model_features(df_test_processed, model_feats_old)\n",
    "    if 'LOS' in df_test_final.columns.tolist():\n",
    "        df_test_final = df_test_final.drop('LOS', axis=1)\n",
    "    preds_old = np.ceil(model.predict(df_test_final))\n",
    "    rmse_old = np.sqrt(metrics.mean_squared_error(df_test_processed['LOS'], preds_old))\n",
    "    mae_old = np.sqrt(metrics.mean_absolute_error(df_test_processed['LOS'], preds_old))\n",
    "    \n",
    "    # Create dictionaries for performance metrics\n",
    "    model_xgb_metrics_old = {'RMSE': rmse_old, 'MAE': mae_old}\n",
    "\n",
    "    return model_xgb_metrics_new, model_xgb_metrics_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict, old_dict = retrain_and_evaluate_model('2022-12-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_model(new_perform_dict, old_perform_dict):\n",
    "    count = 0\n",
    "    for metric in new_perform_dict.keys():\n",
    "        if new_perform_dict[metric] < old_perform_dict[metric]:\n",
    "            count += 1\n",
    "    \n",
    "    if count > 0:\n",
    "        return 'New Model'\n",
    "    else:\n",
    "        return 'Old Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalize_model(new_perform_dict=new_dict, old_perform_dict=old_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def deploy_model(selector='Old Model'):\n",
    "    if selector != 'Old Model':\n",
    "        # Define paths\n",
    "        archive_folder = './Archive/'\n",
    "        retraining_folder = './Retraining Artifacts/'\n",
    "\n",
    "        # Define files to be archived\n",
    "        files_to_archive = [\n",
    "            'MODEL_FEATS.pkl',\n",
    "            'MODEL_XGB.model',\n",
    "            'MODEL_XGB_PERFM_METRICS.pkl'\n",
    "        ]\n",
    "\n",
    "        # Archive old model files\n",
    "        for filename in files_to_archive:\n",
    "            old_filepath = filename\n",
    "            archive_filepath = archive_folder + filename\n",
    "            shutil.move(old_filepath, archive_filepath)\n",
    "\n",
    "        # Replace with new model artifacts\n",
    "        new_files_to_replace = [\n",
    "            'MODEL_FEATS.pkl',\n",
    "            'MODEL_XGB.model',\n",
    "            'MODEL_XGB_PERFM_METRICS.pkl'\n",
    "        ]\n",
    "\n",
    "        # Replace old model files with new model files\n",
    "        for filename in new_files_to_replace:\n",
    "            new_filepath = retraining_folder + filename\n",
    "            old_filepath = filename\n",
    "            shutil.move(new_filepath, old_filepath)\n",
    "\n",
    "    return 'Deployment Successful'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_model('Old Model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
